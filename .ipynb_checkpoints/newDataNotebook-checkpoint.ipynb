{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8c5ae-51b4-4a25-98e1-f44f7bd33ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5609d0-19db-4b90-ac75-74e029ec6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cardio_train.csv',  delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a795226-d5de-4d83-bf38-2b5a4d46dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee509bc-86ca-40df-b3a5-bebb37919852",
   "metadata": {},
   "source": [
    "# Information about the data :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b5ce7-7759-476c-bdad-98a3d703e27e",
   "metadata": {},
   "source": [
    "Source : https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b9566-7b22-4673-aae5-89873cca1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_counts = df['cardio'].value_counts()\n",
    "\n",
    "# Plot a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(num_counts, labels=num_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Percentage of People with Different Heart Disease  (num)')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755ad22-a790-417b-9bbc-bbb442a7a2b7",
   "metadata": {},
   "source": [
    "Dataset has proper distribution of target variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a41a2-0853-454a-a03e-8060d8547273",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee60450-4ce4-4847-b7b6-429b45d1872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=['cardio'])\n",
    "\n",
    "X = data.drop(columns=['id'])\n",
    "y = df['cardio']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4bc3d-3f7a-4ed9-9b95-e1e11ada1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c4cc7-97c2-42a3-9436-a52df90112c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cea10-c25c-45e9-8ee1-1ee35bb28bdc",
   "metadata": {},
   "source": [
    "Normalizing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8715922-7c16-4040-8a1a-71e29f155fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29cd488-7f03-4636-80f2-2e865701a2f4",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ee446-97a8-4e29-967e-8b04e7d4f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],          # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],         # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],         # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],           # Mi nimum number of samples required to be at a leaf node\n",
    "    'class_weight': ['balanced', None],      # Handle class imbalance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c2677-9a14-4fb4-b588-264b231d2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Test only 20 random combinations instead of all\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61610fb2-c856-4b3e-9516-88701f31cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train a new model using the best parameters\n",
    "best_rf_model = random_search.best_estimator_\n",
    "y_pred_tuned = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "print(\"Tuned Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3164a53-203d-4c0d-941d-3830431afea8",
   "metadata": {},
   "source": [
    "# Improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671df5b0-179e-4bde-9de4-f3fa95df6f7a",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432d129-142d-4071-9a54-ee6e783af0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)  # View feature importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae8ae5-e8f5-4063-9c06-2f9dcd7a7231",
   "metadata": {},
   "source": [
    "Age | Objective Feature | age | int (days)\n",
    "\n",
    "Height | Objective Feature | height | int (cm) |\n",
    "\n",
    "Weight | Objective Feature | weight | float (kg) |\n",
    "\n",
    "Gender | Objective Feature | gender | categorical code |\n",
    "\n",
    "Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "\n",
    "Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "\n",
    "Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "\n",
    "Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "\n",
    "Smoking | Subjective Feature | smoke | binary |\n",
    "\n",
    "Alcohol intake | Subjective Feature | alco | binary |\n",
    "\n",
    "Physical activity | Subjective Feature | active | binary |\n",
    "\n",
    "Presence or absence of cardiovascular disease | Target Variable | cardio | binary |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561ab42-b76f-4b28-804b-1a7f51edf400",
   "metadata": {},
   "source": [
    "Systolic blood pressure has the highest importance. As per importance, certain features like smoking are suggested to be dropped. However, this must be thoroughly examined. For now, we are going to compute the performance of a machine learning model that uses only the values with higher importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2923af-0545-4820-bddc-c755b5156a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low-importance features from dataset\n",
    "low_importance_features = ['active', 'smoke', 'gender', 'alco']\n",
    "X_train_filtered = X_train.drop(columns=low_importance_features)\n",
    "X_test_filtered = X_test.drop(columns=low_importance_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc726a-a307-4335-941f-e2bc12daec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
    "X_test_scaled = scaler.transform(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14563a40-ba90-45c5-b328-ba8eb2fcb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Test only 20 random combinations instead of all\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a5281-79ae-40c8-8914-3a53bd0bac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train a new model using the best parameters\n",
    "best_rf_model = random_search.best_estimator_\n",
    "y_pred_tuned = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "print(\"Tuned Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780f7c0-0fb6-4b08-9c42-da76354bf03b",
   "metadata": {},
   "source": [
    "Dropping those features reduced the accuracy. Now, need to combine those features into something useful.\n",
    "Height and weight can be combined into BMI.\n",
    "\n",
    "BMI = weight/(height)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e0b32-28b1-464a-89c6-6e59a412e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['BMI'] = X_test['weight']/((X_test['height']/100)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc76e4-f258-4524-9fe8-fe0a12f608fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropColumns = ['height','weight']\n",
    "X_test.drop(columns=dropColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6bfb5-7d41-481a-9972-28e484029b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['BMI'] = X_train['weight']/((X_train['height']/100)**2)\n",
    "dropColumns = ['height','weight']\n",
    "X_train.drop(columns=dropColumns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
